{"cells":[{"cell_type":"markdown","metadata":{"id":"KJCBukuWzluF"},"source":["# 텍스트를 위한 딥러닝"]},{"cell_type":"markdown","metadata":{"id":"2Cgv__EhzluJ"},"source":["### `TextVectorization` 층 사용하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"umetvu9gzluK"},"outputs":[],"source":["import string\n","\n","class Vectorizer:\n","    def standardize(self, text):\n","        text = text.lower()\n","        return \"\".join(char for char in text if char not in string.punctuation)\n","\n","    def tokenize(self, text):\n","        return text.split()\n","\n","    def make_vocabulary(self, dataset):\n","        self.vocabulary = {\"\": 0, \"[UNK]\": 1}\n","        for text in dataset:\n","            text = self.standardize(text)\n","            tokens = self.tokenize(text)\n","            for token in tokens:\n","                if token not in self.vocabulary:\n","                    self.vocabulary[token] = len(self.vocabulary)\n","        self.inverse_vocabulary = dict(\n","            (v, k) for k, v in self.vocabulary.items())\n","\n","    def encode(self, text):\n","        text = self.standardize(text)\n","        tokens = self.tokenize(text)\n","        return [self.vocabulary.get(token, 1) for token in tokens]\n","\n","    def decode(self, int_sequence):\n","        return \" \".join(\n","            self.inverse_vocabulary.get(i, \"[UNK]\") for i in int_sequence)\n","\n","vectorizer = Vectorizer()\n","dataset = [\n","    \"I write, erase, rewrite\",\n","    \"Erase again, and then\",\n","    \"A poppy blooms.\",\n","]\n","vectorizer.make_vocabulary(dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xO4cauzVzluM","outputId":"31a25855-671f-4795-fa79-7f134e587e64"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2, 3, 5, 7, 1, 5, 6]\n"]}],"source":["test_sentence = \"I write, rewrite, and still rewrite again\"\n","encoded_sentence = vectorizer.encode(test_sentence)\n","print(encoded_sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yN7SvJCJzluN","outputId":"b13d8874-b5fd-4cdb-a694-7be7ea0ebbf1"},"outputs":[{"name":"stdout","output_type":"stream","text":["i write rewrite and [UNK] rewrite again\n"]}],"source":["decoded_sentence = vectorizer.decode(encoded_sentence)\n","print(decoded_sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xDYDPdvGzluO","outputId":"6032e871-4d57-4b51-b0b1-e611af4f3609"},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-05-25 08:59:45.772559: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["from tensorflow.keras.layers import TextVectorization\n","text_vectorization = TextVectorization(\n","    output_mode=\"int\",\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7iRFOlodzluP"},"outputs":[],"source":["import re\n","import string\n","import tensorflow as tf\n","\n","def custom_standardization_fn(string_tensor):\n","    lowercase_string = tf.strings.lower(string_tensor)\n","    return tf.strings.regex_replace(\n","        lowercase_string, f\"[{re.escape(string.punctuation)}]\", \"\")\n","\n","def custom_split_fn(string_tensor):\n","    return tf.strings.split(string_tensor)\n","\n","text_vectorization = TextVectorization(\n","    output_mode=\"int\",\n","    standardize=custom_standardization_fn,\n","    split=custom_split_fn,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"00d-r8CgzluQ"},"outputs":[],"source":["dataset = [\n","    \"I write, erase, rewrite\",\n","    \"Erase again, and then\",\n","    \"A poppy blooms.\",\n","]\n","text_vectorization.adapt(dataset)"]},{"cell_type":"markdown","metadata":{"id":"Hjqm8GY2zluS"},"source":["**어휘 사전 출력하기**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cLOad93pzluS","outputId":"06ce407e-5d13-4870-dcac-477f67e81cf6"},"outputs":[{"data":{"text/plain":["['',\n"," '[UNK]',\n"," 'erase',\n"," 'write',\n"," 'then',\n"," 'rewrite',\n"," 'poppy',\n"," 'i',\n"," 'blooms',\n"," 'and',\n"," 'again',\n"," 'a']"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["text_vectorization.get_vocabulary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8-YPooBszluT","outputId":"e45c512e-873e-4719-e6b8-c5433a872391"},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor([ 7  3  5  9  1  5 10], shape=(7,), dtype=int64)\n"]}],"source":["vocabulary = text_vectorization.get_vocabulary()\n","test_sentence = \"I write, rewrite, and still rewrite again\"\n","encoded_sentence = text_vectorization(test_sentence)\n","print(encoded_sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nq7WGB1ZzluU","outputId":"a2fa1760-e8c7-460f-f09f-a61616829ab9"},"outputs":[{"name":"stdout","output_type":"stream","text":["i write rewrite and [UNK] rewrite again\n"]}],"source":["inverse_vocab = dict(enumerate(vocabulary))\n","decoded_sentence = \" \".join(inverse_vocab[int(i)] for i in encoded_sentence)\n","print(decoded_sentence)"]},{"cell_type":"markdown","metadata":{"id":"8P_LQ1SkzluV"},"source":["## 단어 그룹을 표현하는 두 가지 방법: 집합과 시퀀스"]},{"cell_type":"markdown","metadata":{"id":"g1gdhPCkzluV"},"source":["### IMDB 영화 리뷰 데이터 준비하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hf_-m_MDzluW","outputId":"197f3fa4-ed75-4b48-ff1f-7b0a69a282b8"},"outputs":[{"name":"stdout","output_type":"stream","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 80.2M  100 80.2M    0     0  25.5M      0  0:00:03  0:00:03 --:--:-- 25.5M\n"]}],"source":["!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","!tar -xf aclImdb_v1.tar.gz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VeOoOBhDzluW"},"outputs":[],"source":["!rm -r aclImdb/train/unsup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"In70yIJRzluX","outputId":"2d157ef1-e537-45a4-9cdf-050d9fa01aa2"},"outputs":[{"name":"stdout","output_type":"stream","text":["I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"]}],"source":["!cat aclImdb/train/pos/4077_10.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uE4UrzskzluX"},"outputs":[],"source":["import os, pathlib, shutil, random\n","\n","base_dir = pathlib.Path(\"aclImdb\")\n","val_dir = base_dir / \"val\"\n","train_dir = base_dir / \"train\"\n","for category in (\"neg\", \"pos\"):\n","    os.makedirs(val_dir / category)\n","    files = os.listdir(train_dir / category)\n","    random.Random(1337).shuffle(files)\n","    num_val_samples = int(0.2 * len(files))\n","    val_files = files[-num_val_samples:]\n","    for fname in val_files:\n","        shutil.move(train_dir / category / fname,\n","                    val_dir / category / fname)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RIyW-DeazluY","outputId":"584418e7-4174-45ae-e4ad-9911be805083"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 20000 files belonging to 2 classes.\n","Found 5000 files belonging to 2 classes.\n","Found 25000 files belonging to 2 classes.\n"]}],"source":["from tensorflow import keras\n","batch_size = 32\n","\n","train_ds = keras.utils.text_dataset_from_directory(\n","    \"aclImdb/train\", batch_size=batch_size\n",")\n","val_ds = keras.utils.text_dataset_from_directory(\n","    \"aclImdb/val\", batch_size=batch_size\n",")\n","test_ds = keras.utils.text_dataset_from_directory(\n","    \"aclImdb/test\", batch_size=batch_size\n",")"]},{"cell_type":"markdown","metadata":{"id":"hslEMFm4zluY"},"source":["**첫 번째 배치의 크기와 dtype 출력하기**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E4DVnOCrzluY","outputId":"0656013d-14da-4762-c24d-85b594e3d3b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["inputs.shape: (32,)\n","inputs.dtype: <dtype: 'string'>\n","targets.shape: (32,)\n","targets.dtype: <dtype: 'int32'>\n","inputs[0]: tf.Tensor(b'Loved the movie. Loved the two families crossing paths in history. Only question is if Sam gets killed then how does his family\\'s line continue? He is Madame Zeroni\\'s son and Zero is supposed to be related but no mention of any other children? Hmmmmmmmmm. Never mentioned any other children or wife prior to his speaking with and falling in love with the teacher? Maybe she had a child prior to becoming the kissing Kate Bandit? Even with the mistakes in the movie. Just loved it. The acting was great. Not sure where the story was with Mr. Sir being Marion a women at the end but makes his character even funnier. The other \"counseler\" did seem concerned for the kids but of course maybe not so much. Poor Warden must have had a really stinky childhood to be so mean when she grew up.', shape=(), dtype=string)\n","targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"]}],"source":["for inputs, targets in train_ds:\n","    print(\"inputs.shape:\", inputs.shape)\n","    print(\"inputs.dtype:\", inputs.dtype)\n","    print(\"targets.shape:\", targets.shape)\n","    print(\"targets.dtype:\", targets.dtype)\n","    print(\"inputs[0]:\", inputs[0])\n","    print(\"targets[0]:\", targets[0])\n","    break"]},{"cell_type":"markdown","metadata":{"id":"zJASbP5OzluY"},"source":["### 단어를 집합으로 처리하기: BoW 방식"]},{"cell_type":"markdown","metadata":{"id":"WBwUznGazluZ"},"source":["#### Single words (unigrams) with binary encoding"]},{"cell_type":"markdown","metadata":{"id":"osu8ti7dzluZ"},"source":["**`TextVectorization` 층으로 데이터 전처리하기**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f2VF2k2PzluZ"},"outputs":[],"source":["text_vectorization = TextVectorization(\n","    max_tokens=20000,\n","    output_mode=\"multi_hot\",\n",")\n","text_only_train_ds = train_ds.map(lambda x, y: x)\n","text_vectorization.adapt(text_only_train_ds)\n","\n","binary_1gram_train_ds = train_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","binary_1gram_val_ds = val_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","binary_1gram_test_ds = test_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)"]},{"cell_type":"markdown","metadata":{"id":"RisPuYlUzluZ"},"source":["**이진 유니그램 데이터셋의 출력 확인하기**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uEHWEKHczlua","outputId":"a304a108-fb4b-4b66-b279-97de67205d2f"},"outputs":[{"name":"stdout","output_type":"stream","text":["inputs.shape: (32, 20000)\n","inputs.dtype: <dtype: 'float32'>\n","targets.shape: (32,)\n","targets.dtype: <dtype: 'int32'>\n","inputs[0]: tf.Tensor([1. 0. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n","targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"]}],"source":["for inputs, targets in binary_1gram_train_ds:\n","    print(\"inputs.shape:\", inputs.shape)\n","    print(\"inputs.dtype:\", inputs.dtype)\n","    print(\"targets.shape:\", targets.shape)\n","    print(\"targets.dtype:\", targets.dtype)\n","    print(\"inputs[0]:\", inputs[0])\n","    print(\"targets[0]:\", targets[0])\n","    break"]},{"cell_type":"markdown","metadata":{"id":"dSulbiyPzlua"},"source":["**모델 생성 유틸리티**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3VHrn4zDzlua"},"outputs":[],"source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","def get_model(max_tokens=20000, hidden_dim=16):\n","    inputs = keras.Input(shape=(max_tokens,))\n","    x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n","    x = layers.Dropout(0.5)(x)\n","    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","    model = keras.Model(inputs, outputs)\n","    model.compile(optimizer=\"rmsprop\",\n","                  loss=\"binary_crossentropy\",\n","                  metrics=[\"accuracy\"])\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"x6RZPa1lzlua"},"source":["**이진 유니그램 모델 훈련하고 테스트하기**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UJKwPmNFzlub","outputId":"59201840-4004-48eb-f0d5-5b901eefdaec"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 20000)]           0         \n","                                                                 \n"," dense (Dense)               (None, 16)                320016    \n","                                                                 \n"," dropout (Dropout)           (None, 16)                0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 17        \n","                                                                 \n","=================================================================\n","Total params: 320,033\n","Trainable params: 320,033\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","625/625 [==============================] - 6s 8ms/step - loss: 0.4155 - accuracy: 0.8250 - val_loss: 0.3076 - val_accuracy: 0.8788\n","Epoch 2/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.2760 - accuracy: 0.8974 - val_loss: 0.2889 - val_accuracy: 0.8870\n","Epoch 3/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.2449 - accuracy: 0.9148 - val_loss: 0.3014 - val_accuracy: 0.8856\n","Epoch 4/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.2231 - accuracy: 0.9244 - val_loss: 0.3192 - val_accuracy: 0.8892\n","Epoch 5/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.2193 - accuracy: 0.9279 - val_loss: 0.3320 - val_accuracy: 0.8924\n","Epoch 6/10\n","625/625 [==============================] - 3s 6ms/step - loss: 0.2078 - accuracy: 0.9328 - val_loss: 0.3441 - val_accuracy: 0.8876\n","Epoch 7/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.2123 - accuracy: 0.9344 - val_loss: 0.3547 - val_accuracy: 0.8836\n","Epoch 8/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.2039 - accuracy: 0.9372 - val_loss: 0.3640 - val_accuracy: 0.8826\n","Epoch 9/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.2070 - accuracy: 0.9357 - val_loss: 0.3699 - val_accuracy: 0.8848\n","Epoch 10/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.1940 - accuracy: 0.9413 - val_loss: 0.3766 - val_accuracy: 0.8826\n","782/782 [==============================] - 2s 2ms/step - loss: 0.2894 - accuracy: 0.8872\n","테스트 정확도: 0.887\n"]}],"source":["model = get_model()\n","model.summary()\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\"binary_1gram.keras\",\n","                                    save_best_only=True)\n","]\n","model.fit(binary_1gram_train_ds.cache(),\n","          validation_data=binary_1gram_val_ds.cache(),\n","          epochs=10,\n","          callbacks=callbacks)\n","model = keras.models.load_model(\"binary_1gram.keras\")\n","print(f\"테스트 정확도: {model.evaluate(binary_1gram_test_ds)[1]:.3f}\")"]},{"cell_type":"markdown","metadata":{"id":"v6p6PQOIzlub"},"source":["#### 이진 인코딩을 사용한 바이그램"]},{"cell_type":"markdown","metadata":{"id":"DrdS0DOYzlub"},"source":["**바이그램을 반환하는 `TextVectorization` 층 만들기**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vjEiIn_Fzlub"},"outputs":[],"source":["text_vectorization = TextVectorization(\n","    ngrams=2,\n","    max_tokens=20000,\n","    output_mode=\"multi_hot\",\n",")"]},{"cell_type":"markdown","metadata":{"id":"yAoSodQjzlub"},"source":["**이진 바이그램 모델 훈련하고 테스트하기**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QIxohOtVzlub","outputId":"9c365403-a71e-48e0-d13d-524c46af08d5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 20000)]           0         \n","                                                                 \n"," dense_2 (Dense)             (None, 16)                320016    \n","                                                                 \n"," dropout_1 (Dropout)         (None, 16)                0         \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 17        \n","                                                                 \n","=================================================================\n","Total params: 320,033\n","Trainable params: 320,033\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","625/625 [==============================] - 5s 7ms/step - loss: 0.3730 - accuracy: 0.8468 - val_loss: 0.2730 - val_accuracy: 0.8906\n","Epoch 2/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.2459 - accuracy: 0.9161 - val_loss: 0.2731 - val_accuracy: 0.8956\n","Epoch 3/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.2180 - accuracy: 0.9322 - val_loss: 0.2948 - val_accuracy: 0.8914\n","Epoch 4/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.1987 - accuracy: 0.9393 - val_loss: 0.3062 - val_accuracy: 0.8932\n","Epoch 5/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.1897 - accuracy: 0.9445 - val_loss: 0.3268 - val_accuracy: 0.8876\n","Epoch 6/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.1857 - accuracy: 0.9477 - val_loss: 0.3395 - val_accuracy: 0.8924\n","Epoch 7/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.1835 - accuracy: 0.9479 - val_loss: 0.3587 - val_accuracy: 0.8838\n","Epoch 8/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.1930 - accuracy: 0.9466 - val_loss: 0.3577 - val_accuracy: 0.8820\n","Epoch 9/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.1733 - accuracy: 0.9517 - val_loss: 0.3702 - val_accuracy: 0.8824\n","Epoch 10/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.1758 - accuracy: 0.9514 - val_loss: 0.3756 - val_accuracy: 0.8846\n","782/782 [==============================] - 2s 3ms/step - loss: 0.2750 - accuracy: 0.8942\n","테스트 정확도: 0.894\n"]}],"source":["text_vectorization.adapt(text_only_train_ds)\n","binary_2gram_train_ds = train_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","binary_2gram_val_ds = val_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","binary_2gram_test_ds = test_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","\n","model = get_model()\n","model.summary()\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\"binary_2gram.keras\",\n","                                    save_best_only=True)\n","]\n","model.fit(binary_2gram_train_ds.cache(),\n","          validation_data=binary_2gram_val_ds.cache(),\n","          epochs=10,\n","          callbacks=callbacks)\n","model = keras.models.load_model(\"binary_2gram.keras\")\n","print(f\"테스트 정확도: {model.evaluate(binary_2gram_test_ds)[1]:.3f}\")"]},{"cell_type":"markdown","metadata":{"id":"eQnb6ldszluc"},"source":["#### TF-IDF 인코딩을 사용한 바이그램"]},{"cell_type":"markdown","metadata":{"id":"COtkVjafzluc"},"source":["**토큰 카운트를 반환하는 `TextVectorization` 층**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rKGElqVvzluc"},"outputs":[],"source":["text_vectorization = TextVectorization(\n","    ngrams=2,\n","    max_tokens=20000,\n","    output_mode=\"count\"\n",")"]},{"cell_type":"markdown","metadata":{"id":"-WqdTF4qzluc"},"source":["**TF-IDF 가중치가 적용된 출력을 반환하는 `TextVectorization` 층**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DOsXGgqHzluc"},"outputs":[],"source":["text_vectorization = TextVectorization(\n","    ngrams=2,\n","    max_tokens=20000,\n","    output_mode=\"tf_idf\",\n",")"]},{"cell_type":"markdown","metadata":{"id":"UE13wockzluc"},"source":["**TF-IDF 바이그램 모델 훈련하고 테스트하기**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UAkIwK0dzluc","outputId":"e43f386d-3d5e-4a5f-b37e-14c03e3a04ad"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, 20000)]           0         \n","                                                                 \n"," dense_4 (Dense)             (None, 16)                320016    \n","                                                                 \n"," dropout_2 (Dropout)         (None, 16)                0         \n","                                                                 \n"," dense_5 (Dense)             (None, 1)                 17        \n","                                                                 \n","=================================================================\n","Total params: 320,033\n","Trainable params: 320,033\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","625/625 [==============================] - 6s 8ms/step - loss: 0.4704 - accuracy: 0.7839 - val_loss: 0.3053 - val_accuracy: 0.8752\n","Epoch 2/10\n","625/625 [==============================] - 4s 6ms/step - loss: 0.3121 - accuracy: 0.8764 - val_loss: 0.3384 - val_accuracy: 0.8578\n","Epoch 3/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.2737 - accuracy: 0.8911 - val_loss: 0.3335 - val_accuracy: 0.8834\n","Epoch 4/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.2506 - accuracy: 0.9016 - val_loss: 0.3051 - val_accuracy: 0.8938\n","Epoch 5/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.2376 - accuracy: 0.9046 - val_loss: 0.3323 - val_accuracy: 0.8860\n","Epoch 6/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.2344 - accuracy: 0.9075 - val_loss: 0.3285 - val_accuracy: 0.8956\n","Epoch 7/10\n","625/625 [==============================] - 4s 6ms/step - loss: 0.2367 - accuracy: 0.9065 - val_loss: 0.3395 - val_accuracy: 0.8862\n","Epoch 8/10\n","625/625 [==============================] - 3s 6ms/step - loss: 0.2241 - accuracy: 0.9071 - val_loss: 0.3451 - val_accuracy: 0.8840\n","Epoch 9/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.2209 - accuracy: 0.9112 - val_loss: 0.3389 - val_accuracy: 0.8962\n","Epoch 10/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.2205 - accuracy: 0.9079 - val_loss: 0.3554 - val_accuracy: 0.8788\n","782/782 [==============================] - 2s 3ms/step - loss: 0.3115 - accuracy: 0.8914\n","테스트 정확도: 0.891\n"]}],"source":["# 텐서플로 2.8.x 버전에서 TF-IDF 인코딩을 GPU에서 수행할 때 오류가 발생할 수 있습니다.\n","# 텐서플로 2.9에서 이 이슈가 해결되었지만 코드를 테스트할 시점에 코랩의 텐서플로 버전은 2.8.2이기 때문에 \n","# 에러를 피하기 위해 CPU를 사용하여 텍스트를 변환합니다.\n","with tf.device(\"cpu\"):\n","    text_vectorization.adapt(text_only_train_ds)\n","\n","tfidf_2gram_train_ds = train_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","tfidf_2gram_val_ds = val_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","tfidf_2gram_test_ds = test_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","\n","model = get_model()\n","model.summary()\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\"tfidf_2gram.keras\",\n","                                    save_best_only=True)\n","]\n","model.fit(tfidf_2gram_train_ds.cache(),\n","          validation_data=tfidf_2gram_val_ds.cache(),\n","          epochs=10,\n","          callbacks=callbacks)\n","model = keras.models.load_model(\"tfidf_2gram.keras\")\n","print(f\"테스트 정확도: {model.evaluate(tfidf_2gram_test_ds)[1]:.3f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ttgc1Ecyzluc"},"outputs":[],"source":["inputs = keras.Input(shape=(1,), dtype=\"string\")\n","processed_inputs = text_vectorization(inputs)\n","outputs = model(processed_inputs)\n","inference_model = keras.Model(inputs, outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gArQOIIxzlud","outputId":"6850c99f-70b8-4ee2-a4bd-2f8496929ffe"},"outputs":[{"name":"stdout","output_type":"stream","text":["긍정적인 리뷰일 확률: 98.91 퍼센트\n"]}],"source":["import tensorflow as tf\n","raw_text_data = tf.convert_to_tensor([\n","    [\"That was an excellent movie, I loved it.\"],\n","])\n","predictions = inference_model(raw_text_data)\n","print(f\"긍정적인 리뷰일 확률: {float(predictions[0] * 100):.2f} 퍼센트\")"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Ch11. 텍스트를 위한 딥러닝.ipynb","provenance":[]},"kernelspec":{"display_name":"default:Python","language":"python","name":"conda-env-default-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"}},"nbformat":4,"nbformat_minor":0}