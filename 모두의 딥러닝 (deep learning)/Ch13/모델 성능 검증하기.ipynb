{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"모델 성능 검증하기.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM90PeUF8HGlorTynmwdmJd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["데이터 탐색"],"metadata":{"id":"G2P55wX2wIsv"}},{"cell_type":"code","source":["import pandas as pd\n","\n","!git clone https://github.com/taehojo/data.git\n","\n","df = pd.read_csv('./data/sonar3.csv', header=None)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fbMfVAIGwKnO","executionInfo":{"status":"ok","timestamp":1650370798208,"user_tz":-540,"elapsed":1794,"user":{"displayName":"박준규","userId":"16577167999398926509"}},"outputId":"11dbddb0-be3d-42b7-a22a-7470c20ed07b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'data'...\n","remote: Enumerating objects: 21, done.\u001b[K\n","remote: Counting objects: 100% (21/21), done.\u001b[K\n","remote: Compressing objects: 100% (18/18), done.\u001b[K\n","remote: Total 21 (delta 3), reused 20 (delta 2), pack-reused 0\u001b[K\n","Unpacking objects: 100% (21/21), done.\n"]}]},{"cell_type":"code","source":["df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299},"id":"X2oUJxw1w69C","executionInfo":{"status":"ok","timestamp":1650370803000,"user_tz":-540,"elapsed":9,"user":{"displayName":"박준규","userId":"16577167999398926509"}},"outputId":"b5393818-a543-4740-bd56-8492bcaf1c75"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       0       1       2       3       4       5       6       7       8   \\\n","0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n","1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n","2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n","3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n","4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n","\n","       9   ...      51      52      53      54      55      56      57  \\\n","0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n","1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n","2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n","3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n","4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n","\n","       58      59  60  \n","0  0.0090  0.0032   0  \n","1  0.0052  0.0044   0  \n","2  0.0095  0.0078   0  \n","3  0.0040  0.0117   0  \n","4  0.0107  0.0094   0  \n","\n","[5 rows x 61 columns]"],"text/html":["\n","  <div id=\"df-1366112e-47ab-4d39-9df1-8bf2d692459b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>51</th>\n","      <th>52</th>\n","      <th>53</th>\n","      <th>54</th>\n","      <th>55</th>\n","      <th>56</th>\n","      <th>57</th>\n","      <th>58</th>\n","      <th>59</th>\n","      <th>60</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0200</td>\n","      <td>0.0371</td>\n","      <td>0.0428</td>\n","      <td>0.0207</td>\n","      <td>0.0954</td>\n","      <td>0.0986</td>\n","      <td>0.1539</td>\n","      <td>0.1601</td>\n","      <td>0.3109</td>\n","      <td>0.2111</td>\n","      <td>...</td>\n","      <td>0.0027</td>\n","      <td>0.0065</td>\n","      <td>0.0159</td>\n","      <td>0.0072</td>\n","      <td>0.0167</td>\n","      <td>0.0180</td>\n","      <td>0.0084</td>\n","      <td>0.0090</td>\n","      <td>0.0032</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0453</td>\n","      <td>0.0523</td>\n","      <td>0.0843</td>\n","      <td>0.0689</td>\n","      <td>0.1183</td>\n","      <td>0.2583</td>\n","      <td>0.2156</td>\n","      <td>0.3481</td>\n","      <td>0.3337</td>\n","      <td>0.2872</td>\n","      <td>...</td>\n","      <td>0.0084</td>\n","      <td>0.0089</td>\n","      <td>0.0048</td>\n","      <td>0.0094</td>\n","      <td>0.0191</td>\n","      <td>0.0140</td>\n","      <td>0.0049</td>\n","      <td>0.0052</td>\n","      <td>0.0044</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0262</td>\n","      <td>0.0582</td>\n","      <td>0.1099</td>\n","      <td>0.1083</td>\n","      <td>0.0974</td>\n","      <td>0.2280</td>\n","      <td>0.2431</td>\n","      <td>0.3771</td>\n","      <td>0.5598</td>\n","      <td>0.6194</td>\n","      <td>...</td>\n","      <td>0.0232</td>\n","      <td>0.0166</td>\n","      <td>0.0095</td>\n","      <td>0.0180</td>\n","      <td>0.0244</td>\n","      <td>0.0316</td>\n","      <td>0.0164</td>\n","      <td>0.0095</td>\n","      <td>0.0078</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0100</td>\n","      <td>0.0171</td>\n","      <td>0.0623</td>\n","      <td>0.0205</td>\n","      <td>0.0205</td>\n","      <td>0.0368</td>\n","      <td>0.1098</td>\n","      <td>0.1276</td>\n","      <td>0.0598</td>\n","      <td>0.1264</td>\n","      <td>...</td>\n","      <td>0.0121</td>\n","      <td>0.0036</td>\n","      <td>0.0150</td>\n","      <td>0.0085</td>\n","      <td>0.0073</td>\n","      <td>0.0050</td>\n","      <td>0.0044</td>\n","      <td>0.0040</td>\n","      <td>0.0117</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0762</td>\n","      <td>0.0666</td>\n","      <td>0.0481</td>\n","      <td>0.0394</td>\n","      <td>0.0590</td>\n","      <td>0.0649</td>\n","      <td>0.1209</td>\n","      <td>0.2467</td>\n","      <td>0.3564</td>\n","      <td>0.4459</td>\n","      <td>...</td>\n","      <td>0.0031</td>\n","      <td>0.0054</td>\n","      <td>0.0105</td>\n","      <td>0.0110</td>\n","      <td>0.0015</td>\n","      <td>0.0072</td>\n","      <td>0.0048</td>\n","      <td>0.0107</td>\n","      <td>0.0094</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 61 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1366112e-47ab-4d39-9df1-8bf2d692459b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1366112e-47ab-4d39-9df1-8bf2d692459b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1366112e-47ab-4d39-9df1-8bf2d692459b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["df[60].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RpP4cq5Gw-yt","executionInfo":{"status":"ok","timestamp":1650370845716,"user_tz":-540,"elapsed":299,"user":{"displayName":"박준규","userId":"16577167999398926509"}},"outputId":"0c503049-efe2-4b57-8489-7491bee547aa"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    111\n","0     97\n","Name: 60, dtype: int64"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["X = df.iloc[:,0:60]\n","y = df.iloc[:,60]"],"metadata":{"id":"rXtai4AQxJhE","executionInfo":{"status":"ok","timestamp":1650370873661,"user_tz":-540,"elapsed":5,"user":{"displayName":"박준규","userId":"16577167999398926509"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["초음파 광물 예측"],"metadata":{"id":"wIYOA9GQxR8u"}},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense"],"metadata":{"id":"rIJk1NVLxZ2-","executionInfo":{"status":"ok","timestamp":1650370937530,"user_tz":-540,"elapsed":544,"user":{"displayName":"박준규","userId":"16577167999398926509"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","model = Sequential()\n","model.add(Dense(24,  input_dim=60, activation='relu'))\n","model.add(Dense(10, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","history=model.fit(X, y, epochs=200, batch_size=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m5NdK22Bxf0z","executionInfo":{"status":"ok","timestamp":1650371174918,"user_tz":-540,"elapsed":10944,"user":{"displayName":"박준규","userId":"16577167999398926509"}},"outputId":"fb87c279-5859-46b5-e038-10a03b8ff2b6"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","21/21 [==============================] - 1s 2ms/step - loss: 0.6978 - accuracy: 0.5481\n","Epoch 2/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.6591 - accuracy: 0.5817\n","Epoch 3/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.6419 - accuracy: 0.6298\n","Epoch 4/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.6538\n","Epoch 5/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.6042 - accuracy: 0.7019\n","Epoch 6/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.5884 - accuracy: 0.7163\n","Epoch 7/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.5683 - accuracy: 0.7837\n","Epoch 8/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.7452\n","Epoch 9/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7933\n","Epoch 10/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.8077\n","Epoch 11/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7692\n","Epoch 12/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.8365\n","Epoch 13/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.8029\n","Epoch 14/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.8173\n","Epoch 15/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.8029\n","Epoch 16/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.8317\n","Epoch 17/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8365\n","Epoch 18/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.8365\n","Epoch 19/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8413\n","Epoch 20/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8510\n","Epoch 21/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.8365\n","Epoch 22/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.3784 - accuracy: 0.8510\n","Epoch 23/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8462\n","Epoch 24/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8462\n","Epoch 25/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8558\n","Epoch 26/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8606\n","Epoch 27/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8750\n","Epoch 28/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.3433 - accuracy: 0.8702\n","Epoch 29/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.3451 - accuracy: 0.8558\n","Epoch 30/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.8654\n","Epoch 31/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8654\n","Epoch 32/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8702\n","Epoch 33/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8702\n","Epoch 34/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.3197 - accuracy: 0.8702\n","Epoch 35/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.3172 - accuracy: 0.8798\n","Epoch 36/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8702\n","Epoch 37/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8606\n","Epoch 38/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.8990\n","Epoch 39/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2971 - accuracy: 0.8990\n","Epoch 40/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2953 - accuracy: 0.8942\n","Epoch 41/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2935 - accuracy: 0.8942\n","Epoch 42/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2773 - accuracy: 0.9087\n","Epoch 43/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2887 - accuracy: 0.8942\n","Epoch 44/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2864 - accuracy: 0.9038\n","Epoch 45/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2768 - accuracy: 0.9087\n","Epoch 46/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2897 - accuracy: 0.8942\n","Epoch 47/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2710 - accuracy: 0.9038\n","Epoch 48/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2700 - accuracy: 0.9135\n","Epoch 49/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2655 - accuracy: 0.8990\n","Epoch 50/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2662 - accuracy: 0.9038\n","Epoch 51/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2712 - accuracy: 0.9183\n","Epoch 52/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2555 - accuracy: 0.9087\n","Epoch 53/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.9183\n","Epoch 54/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2516 - accuracy: 0.9038\n","Epoch 55/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.9183\n","Epoch 56/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2419 - accuracy: 0.9375\n","Epoch 57/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2427 - accuracy: 0.9135\n","Epoch 58/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2360 - accuracy: 0.9135\n","Epoch 59/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2306 - accuracy: 0.9279\n","Epoch 60/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2312 - accuracy: 0.9279\n","Epoch 61/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2273 - accuracy: 0.9279\n","Epoch 62/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.2326 - accuracy: 0.9279\n","Epoch 63/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2238 - accuracy: 0.9327\n","Epoch 64/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2226 - accuracy: 0.9279\n","Epoch 65/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2141 - accuracy: 0.9375\n","Epoch 66/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2183 - accuracy: 0.9231\n","Epoch 67/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2128 - accuracy: 0.9327\n","Epoch 68/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2142 - accuracy: 0.9375\n","Epoch 69/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2069 - accuracy: 0.9375\n","Epoch 70/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.2015 - accuracy: 0.9327\n","Epoch 71/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1991 - accuracy: 0.9327\n","Epoch 72/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1969 - accuracy: 0.9375\n","Epoch 73/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1999 - accuracy: 0.9423\n","Epoch 74/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1962 - accuracy: 0.9279\n","Epoch 75/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1891 - accuracy: 0.9279\n","Epoch 76/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1888 - accuracy: 0.9327\n","Epoch 77/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1856 - accuracy: 0.9375\n","Epoch 78/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1835 - accuracy: 0.9423\n","Epoch 79/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1797 - accuracy: 0.9471\n","Epoch 80/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.9423\n","Epoch 81/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1722 - accuracy: 0.9471\n","Epoch 82/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1704 - accuracy: 0.9423\n","Epoch 83/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1737 - accuracy: 0.9471\n","Epoch 84/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1670 - accuracy: 0.9519\n","Epoch 85/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1709 - accuracy: 0.9375\n","Epoch 86/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1657 - accuracy: 0.9423\n","Epoch 87/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.9375\n","Epoch 88/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1573 - accuracy: 0.9471\n","Epoch 89/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1602 - accuracy: 0.9471\n","Epoch 90/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1580 - accuracy: 0.9615\n","Epoch 91/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1533 - accuracy: 0.9471\n","Epoch 92/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1534 - accuracy: 0.9423\n","Epoch 93/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1477 - accuracy: 0.9519\n","Epoch 94/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1413 - accuracy: 0.9567\n","Epoch 95/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1462 - accuracy: 0.9471\n","Epoch 96/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1499 - accuracy: 0.9423\n","Epoch 97/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1408 - accuracy: 0.9471\n","Epoch 98/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1335 - accuracy: 0.9567\n","Epoch 99/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1348 - accuracy: 0.9519\n","Epoch 100/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1397 - accuracy: 0.9567\n","Epoch 101/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1432 - accuracy: 0.9519\n","Epoch 102/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1340 - accuracy: 0.9519\n","Epoch 103/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1430 - accuracy: 0.9375\n","Epoch 104/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1281 - accuracy: 0.9663\n","Epoch 105/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1331 - accuracy: 0.9519\n","Epoch 106/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1166 - accuracy: 0.9615\n","Epoch 107/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1177 - accuracy: 0.9615\n","Epoch 108/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1124 - accuracy: 0.9663\n","Epoch 109/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1104 - accuracy: 0.9615\n","Epoch 110/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1099 - accuracy: 0.9519\n","Epoch 111/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1111 - accuracy: 0.9519\n","Epoch 112/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1045 - accuracy: 0.9760\n","Epoch 113/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1025 - accuracy: 0.9760\n","Epoch 114/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1042 - accuracy: 0.9663\n","Epoch 115/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0983 - accuracy: 0.9712\n","Epoch 116/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0978 - accuracy: 0.9712\n","Epoch 117/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1038 - accuracy: 0.9712\n","Epoch 118/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1085 - accuracy: 0.9712\n","Epoch 119/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.1191 - accuracy: 0.9471\n","Epoch 120/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0954 - accuracy: 0.9760\n","Epoch 121/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0905 - accuracy: 0.9808\n","Epoch 122/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0910 - accuracy: 0.9808\n","Epoch 123/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0848 - accuracy: 0.9856\n","Epoch 124/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0850 - accuracy: 0.9856\n","Epoch 125/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0818 - accuracy: 0.9856\n","Epoch 126/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0806 - accuracy: 0.9808\n","Epoch 127/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0797 - accuracy: 0.9808\n","Epoch 128/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0776 - accuracy: 0.9856\n","Epoch 129/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0745 - accuracy: 0.9856\n","Epoch 130/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0741 - accuracy: 0.9856\n","Epoch 131/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0761 - accuracy: 0.9904\n","Epoch 132/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0715 - accuracy: 0.9856\n","Epoch 133/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0788 - accuracy: 0.9856\n","Epoch 134/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0747 - accuracy: 0.9904\n","Epoch 135/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0680 - accuracy: 0.9856\n","Epoch 136/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.9856\n","Epoch 137/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.9904\n","Epoch 138/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.9904\n","Epoch 139/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.9856\n","Epoch 140/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0612 - accuracy: 0.9952\n","Epoch 141/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 0.9904\n","Epoch 142/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0600 - accuracy: 0.9904\n","Epoch 143/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.9904\n","Epoch 144/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.9904\n","Epoch 145/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.9904\n","Epoch 146/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.9952\n","Epoch 147/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9952\n","Epoch 148/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0569 - accuracy: 0.9904\n","Epoch 149/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.9856\n","Epoch 150/200\n","21/21 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9904\n","Epoch 151/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 1.0000\n","Epoch 152/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0489 - accuracy: 1.0000\n","Epoch 153/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0464 - accuracy: 0.9952\n","Epoch 154/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 0.9952\n","Epoch 155/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0483 - accuracy: 0.9952\n","Epoch 156/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0455 - accuracy: 1.0000\n","Epoch 157/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0448 - accuracy: 1.0000\n","Epoch 158/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0429 - accuracy: 0.9952\n","Epoch 159/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0433 - accuracy: 1.0000\n","Epoch 160/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 1.0000\n","Epoch 161/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0414 - accuracy: 1.0000\n","Epoch 162/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 1.0000\n","Epoch 163/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 1.0000\n","Epoch 164/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 1.0000\n","Epoch 165/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9952\n","Epoch 166/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9952\n","Epoch 167/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 1.0000\n","Epoch 168/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 0.9904\n","Epoch 169/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 1.0000\n","Epoch 170/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 1.0000\n","Epoch 171/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0321 - accuracy: 1.0000\n","Epoch 172/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0326 - accuracy: 1.0000\n","Epoch 173/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 1.0000\n","Epoch 174/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 1.0000\n","Epoch 175/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.9952\n","Epoch 176/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 1.0000\n","Epoch 177/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9952\n","Epoch 178/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 1.0000\n","Epoch 179/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 1.0000\n","Epoch 180/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 1.0000\n","Epoch 181/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 1.0000\n","Epoch 182/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 1.0000\n","Epoch 183/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 1.0000\n","Epoch 184/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 1.0000\n","Epoch 185/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 1.0000\n","Epoch 186/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 1.0000\n","Epoch 187/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0248 - accuracy: 1.0000\n","Epoch 188/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 1.0000\n","Epoch 189/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 1.0000\n","Epoch 190/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 1.0000\n","Epoch 191/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 1.0000\n","Epoch 192/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 1.0000\n","Epoch 193/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 1.0000\n","Epoch 194/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 1.0000\n","Epoch 195/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 1.0000\n","Epoch 196/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 1.0000\n","Epoch 197/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 1.0000\n","Epoch 198/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 1.0000\n","Epoch 199/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 1.0000\n","Epoch 200/200\n","21/21 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 1.0000\n"]}]},{"cell_type":"markdown","source":["과적합 방지 - 학습/테스트 구분"],"metadata":{"id":"REDCoWET0WFh"}},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from sklearn.model_selection import train_test_split\n","\n","import pandas as pd\n","\n","!git clone https://github.com/taehojo/data.git\n","\n","df = pd.read_csv('./data/sonar3.csv', header=None)\n","\n","X = df.iloc[:,0:60]\n","y = df.iloc[:,60]\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)\n","\n","model = Sequential()\n","model.add(Dense(24,  input_dim=60, activation='relu'))\n","model.add(Dense(10, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","history=model.fit(X_train, y_train, epochs=200, batch_size=10)\n","\n","score=model.evaluate(X_test, y_test)\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oWshRKG40aBQ","executionInfo":{"status":"ok","timestamp":1650372617140,"user_tz":-540,"elapsed":9087,"user":{"displayName":"박준규","userId":"16577167999398926509"}},"outputId":"c73af2b6-7014-4f34-93b2-370090cdb548"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'data' already exists and is not an empty directory.\n","Epoch 1/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.5586\n","Epoch 2/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.6641 - accuracy: 0.5586\n","Epoch 3/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.5586\n","Epoch 4/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.6318 - accuracy: 0.6345\n","Epoch 5/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.6168 - accuracy: 0.6828\n","Epoch 6/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.6045 - accuracy: 0.6690\n","Epoch 7/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.5900 - accuracy: 0.6966\n","Epoch 8/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.7379\n","Epoch 9/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.7103\n","Epoch 10/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7310\n","Epoch 11/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.5431 - accuracy: 0.7862\n","Epoch 12/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7862\n","Epoch 13/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7586\n","Epoch 14/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.8000\n","Epoch 15/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.8000\n","Epoch 16/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7655\n","Epoch 17/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.8069\n","Epoch 18/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.8207\n","Epoch 19/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7931\n","Epoch 20/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.8414\n","Epoch 21/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.8276\n","Epoch 22/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8138\n","Epoch 23/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8138\n","Epoch 24/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8552\n","Epoch 25/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4028 - accuracy: 0.8552\n","Epoch 26/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8483\n","Epoch 27/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.8621\n","Epoch 28/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8483\n","Epoch 29/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8414\n","Epoch 30/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8345\n","Epoch 31/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8690\n","Epoch 32/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3734 - accuracy: 0.8621\n","Epoch 33/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8552\n","Epoch 34/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8621\n","Epoch 35/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3591 - accuracy: 0.8621\n","Epoch 36/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8000\n","Epoch 37/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8759\n","Epoch 38/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8621\n","Epoch 39/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3391 - accuracy: 0.8828\n","Epoch 40/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8828\n","Epoch 41/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8897\n","Epoch 42/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.3260 - accuracy: 0.8966\n","Epoch 43/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8828\n","Epoch 44/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8552\n","Epoch 45/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.8828\n","Epoch 46/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.3258 - accuracy: 0.8759\n","Epoch 47/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3187 - accuracy: 0.8897\n","Epoch 48/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8897\n","Epoch 49/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8897\n","Epoch 50/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8897\n","Epoch 51/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8552\n","Epoch 52/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.8759\n","Epoch 53/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3007 - accuracy: 0.8897\n","Epoch 54/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2984 - accuracy: 0.8897\n","Epoch 55/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2867 - accuracy: 0.8966\n","Epoch 56/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2889 - accuracy: 0.8828\n","Epoch 57/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2874 - accuracy: 0.8897\n","Epoch 58/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2836 - accuracy: 0.8828\n","Epoch 59/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2775 - accuracy: 0.8966\n","Epoch 60/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2789 - accuracy: 0.8966\n","Epoch 61/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2773 - accuracy: 0.9103\n","Epoch 62/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2917 - accuracy: 0.8966\n","Epoch 63/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2759 - accuracy: 0.8828\n","Epoch 64/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2668 - accuracy: 0.8966\n","Epoch 65/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2691 - accuracy: 0.8966\n","Epoch 66/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2634 - accuracy: 0.8828\n","Epoch 67/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.9172\n","Epoch 68/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2622 - accuracy: 0.8897\n","Epoch 69/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2734 - accuracy: 0.8966\n","Epoch 70/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2540 - accuracy: 0.9172\n","Epoch 71/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2545 - accuracy: 0.8759\n","Epoch 72/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2474 - accuracy: 0.9034\n","Epoch 73/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2574 - accuracy: 0.9034\n","Epoch 74/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2558 - accuracy: 0.8966\n","Epoch 75/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.9103\n","Epoch 76/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.9034\n","Epoch 77/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.9034\n","Epoch 78/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.9034\n","Epoch 79/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2345 - accuracy: 0.8966\n","Epoch 80/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2308 - accuracy: 0.9103\n","Epoch 81/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2350 - accuracy: 0.9103\n","Epoch 82/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2340 - accuracy: 0.8897\n","Epoch 83/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2294 - accuracy: 0.9034\n","Epoch 84/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2229 - accuracy: 0.9103\n","Epoch 85/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2265 - accuracy: 0.9103\n","Epoch 86/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.9241\n","Epoch 87/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2245 - accuracy: 0.9034\n","Epoch 88/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2205 - accuracy: 0.9172\n","Epoch 89/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.2158 - accuracy: 0.9310\n","Epoch 90/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2171 - accuracy: 0.9103\n","Epoch 91/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2147 - accuracy: 0.9241\n","Epoch 92/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2086 - accuracy: 0.9310\n","Epoch 93/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2049 - accuracy: 0.9241\n","Epoch 94/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2036 - accuracy: 0.9310\n","Epoch 95/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2002 - accuracy: 0.9310\n","Epoch 96/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.2004 - accuracy: 0.9310\n","Epoch 97/200\n","15/15 [==============================] - 0s 4ms/step - loss: 0.2006 - accuracy: 0.9172\n","Epoch 98/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 0.9241\n","Epoch 99/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.9172\n","Epoch 100/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2147 - accuracy: 0.9034\n","Epoch 101/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2134 - accuracy: 0.9241\n","Epoch 102/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2214 - accuracy: 0.9241\n","Epoch 103/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2100 - accuracy: 0.9034\n","Epoch 104/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1885 - accuracy: 0.9379\n","Epoch 105/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.9310\n","Epoch 106/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1826 - accuracy: 0.9241\n","Epoch 107/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1831 - accuracy: 0.9310\n","Epoch 108/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9310\n","Epoch 109/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1770 - accuracy: 0.9379\n","Epoch 110/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1732 - accuracy: 0.9379\n","Epoch 111/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1714 - accuracy: 0.9448\n","Epoch 112/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.9241\n","Epoch 113/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.1798 - accuracy: 0.9310\n","Epoch 114/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9448\n","Epoch 115/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1671 - accuracy: 0.9448\n","Epoch 116/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1645 - accuracy: 0.9379\n","Epoch 117/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.9379\n","Epoch 118/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1737 - accuracy: 0.9241\n","Epoch 119/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1704 - accuracy: 0.9310\n","Epoch 120/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1820 - accuracy: 0.9517\n","Epoch 121/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.9379\n","Epoch 122/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1586 - accuracy: 0.9448\n","Epoch 123/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1525 - accuracy: 0.9448\n","Epoch 124/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.1557 - accuracy: 0.9517\n","Epoch 125/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1535 - accuracy: 0.9517\n","Epoch 126/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1476 - accuracy: 0.9517\n","Epoch 127/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1467 - accuracy: 0.9517\n","Epoch 128/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1558 - accuracy: 0.9517\n","Epoch 129/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1464 - accuracy: 0.9517\n","Epoch 130/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1408 - accuracy: 0.9586\n","Epoch 131/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1438 - accuracy: 0.9448\n","Epoch 132/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1403 - accuracy: 0.9517\n","Epoch 133/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1427 - accuracy: 0.9517\n","Epoch 134/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1427 - accuracy: 0.9517\n","Epoch 135/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1363 - accuracy: 0.9448\n","Epoch 136/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1371 - accuracy: 0.9586\n","Epoch 137/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1464 - accuracy: 0.9517\n","Epoch 138/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1312 - accuracy: 0.9586\n","Epoch 139/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1349 - accuracy: 0.9448\n","Epoch 140/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 0.9655\n","Epoch 141/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1288 - accuracy: 0.9517\n","Epoch 142/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1240 - accuracy: 0.9655\n","Epoch 143/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1255 - accuracy: 0.9586\n","Epoch 144/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1231 - accuracy: 0.9655\n","Epoch 145/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1225 - accuracy: 0.9517\n","Epoch 146/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1192 - accuracy: 0.9724\n","Epoch 147/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1181 - accuracy: 0.9586\n","Epoch 148/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1189 - accuracy: 0.9724\n","Epoch 149/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1169 - accuracy: 0.9586\n","Epoch 150/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1134 - accuracy: 0.9655\n","Epoch 151/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1122 - accuracy: 0.9655\n","Epoch 152/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1115 - accuracy: 0.9655\n","Epoch 153/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1162 - accuracy: 0.9586\n","Epoch 154/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1156 - accuracy: 0.9586\n","Epoch 155/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1097 - accuracy: 0.9793\n","Epoch 156/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1047 - accuracy: 0.9586\n","Epoch 157/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1058 - accuracy: 0.9655\n","Epoch 158/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1051 - accuracy: 0.9724\n","Epoch 159/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1013 - accuracy: 0.9724\n","Epoch 160/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0996 - accuracy: 0.9655\n","Epoch 161/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0978 - accuracy: 0.9724\n","Epoch 162/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1016 - accuracy: 0.9793\n","Epoch 163/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1079 - accuracy: 0.9448\n","Epoch 164/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0977 - accuracy: 0.9655\n","Epoch 165/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0929 - accuracy: 0.9724\n","Epoch 166/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0954 - accuracy: 0.9724\n","Epoch 167/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0893 - accuracy: 0.9793\n","Epoch 168/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0885 - accuracy: 0.9793\n","Epoch 169/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0885 - accuracy: 0.9724\n","Epoch 170/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0913 - accuracy: 0.9724\n","Epoch 171/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0881 - accuracy: 0.9793\n","Epoch 172/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0996 - accuracy: 0.9586\n","Epoch 173/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0891 - accuracy: 0.9724\n","Epoch 174/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0829 - accuracy: 0.9724\n","Epoch 175/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0809 - accuracy: 0.9724\n","Epoch 176/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0811 - accuracy: 0.9862\n","Epoch 177/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0815 - accuracy: 0.9724\n","Epoch 178/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0785 - accuracy: 0.9793\n","Epoch 179/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0777 - accuracy: 0.9724\n","Epoch 180/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0780 - accuracy: 0.9724\n","Epoch 181/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0763 - accuracy: 0.9862\n","Epoch 182/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0819 - accuracy: 0.9793\n","Epoch 183/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0776 - accuracy: 0.9793\n","Epoch 184/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0749 - accuracy: 0.9724\n","Epoch 185/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0745 - accuracy: 0.9862\n","Epoch 186/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0713 - accuracy: 0.9793\n","Epoch 187/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0692 - accuracy: 0.9862\n","Epoch 188/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0781 - accuracy: 0.9724\n","Epoch 189/200\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0743 - accuracy: 0.9793\n","Epoch 190/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0779 - accuracy: 0.9724\n","Epoch 191/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.9793\n","Epoch 192/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.9862\n","Epoch 193/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.9931\n","Epoch 194/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.9862\n","Epoch 195/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.9931\n","Epoch 196/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.9931\n","Epoch 197/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.9931\n","Epoch 198/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.9793\n","Epoch 199/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.9931\n","Epoch 200/200\n","15/15 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.9931\n","2/2 [==============================] - 0s 7ms/step - loss: 0.4596 - accuracy: 0.8413\n","Test accuracy: 0.841269850730896\n"]}]},{"cell_type":"markdown","source":["모델 저장과 재사용"],"metadata":{"id":"J0P7GToR4CEB"}},{"cell_type":"code","source":["model.save('./data/model/my_model.hdf5')"],"metadata":{"id":"95kq_6BV4FIi","executionInfo":{"status":"ok","timestamp":1650372959973,"user_tz":-540,"elapsed":280,"user":{"displayName":"박준규","userId":"16577167999398926509"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential, load_model"],"metadata":{"id":"UdsM15si5NsJ","executionInfo":{"status":"ok","timestamp":1650373042601,"user_tz":-540,"elapsed":314,"user":{"displayName":"박준규","userId":"16577167999398926509"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["del model"],"metadata":{"id":"8JdgqbDn5hwh","executionInfo":{"status":"ok","timestamp":1650373046484,"user_tz":-540,"elapsed":2,"user":{"displayName":"박준규","userId":"16577167999398926509"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["model = load_model('./data/model/my_model.hdf5')"],"metadata":{"id":"iPFxpeKY5i2L","executionInfo":{"status":"ok","timestamp":1650373084104,"user_tz":-540,"elapsed":293,"user":{"displayName":"박준규","userId":"16577167999398926509"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["score = model.evaluate(X_test, y_test) \n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-BOXqXiI5prU","executionInfo":{"status":"ok","timestamp":1650373152188,"user_tz":-540,"elapsed":790,"user":{"displayName":"박준규","userId":"16577167999398926509"}},"outputId":"f8ce1674-0cd6-499c-f960-48dc096d48fe"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["2/2 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.8413\n","Test accuracy: 0.841269850730896\n"]}]},{"cell_type":"markdown","source":["k겹 교차 검증"],"metadata":{"id":"pPwcJff159ty"}},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import accuracy_score\n","\n","import pandas as pd"],"metadata":{"id":"u_UZR56M6AdD","executionInfo":{"status":"ok","timestamp":1650373594893,"user_tz":-540,"elapsed":354,"user":{"displayName":"박준규","userId":"16577167999398926509"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/taehojo/data.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v3aZlk5Q7orY","executionInfo":{"status":"ok","timestamp":1650373617584,"user_tz":-540,"elapsed":290,"user":{"displayName":"박준규","userId":"16577167999398926509"}},"outputId":"f77a73f5-84b1-418b-93d3-2130e1ac752b"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'data' already exists and is not an empty directory.\n"]}]},{"cell_type":"code","source":["df = pd.read_csv('./data/sonar3.csv', header=None)"],"metadata":{"id":"BX5Zj3jP7uOi","executionInfo":{"status":"ok","timestamp":1650373661100,"user_tz":-540,"elapsed":300,"user":{"displayName":"박준규","userId":"16577167999398926509"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["X = df.iloc[:,0:60]\n","y = df.iloc[:,60]"],"metadata":{"id":"XgiRk2PH743J","executionInfo":{"status":"ok","timestamp":1650373689581,"user_tz":-540,"elapsed":271,"user":{"displayName":"박준규","userId":"16577167999398926509"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["k=5\n","\n","kfold = KFold(n_splits=k, shuffle=True)\n","\n","acc_score = []\n","\n","def model_fn():\n","  model = Sequential()\n","  model.add(Dense(24, input_dim=60, activation='relu'))\n","  model.add(Dense(10, activation='relu'))\n","  model.add(Dense(1,  activation='sigmoid'))\n","  return model"],"metadata":{"id":"rl_Zogsa7_0d","executionInfo":{"status":"ok","timestamp":1650373874687,"user_tz":-540,"elapsed":284,"user":{"displayName":"박준규","userId":"16577167999398926509"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["for train_index, test_index in kfold.split(X):\n","  X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n","  y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","\n","  model = model_fn()\n","  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  history = model.fit(X_train, y_train, epochs=200, batch_size=10, verbose=0)\n","  accuracy = model.evaluate(X_test, y_test)[1]\n","  acc_score.append(accuracy)\n","\n","avg_acc_score = sum(acc_score) / k\n","\n","print('정확도: ', acc_score)\n","print('정확도 평균: ', avg_acc_score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fD-Ih-J58tBH","executionInfo":{"status":"ok","timestamp":1650374218634,"user_tz":-540,"elapsed":34510,"user":{"displayName":"박준규","userId":"16577167999398926509"}},"outputId":"2698d303-00b8-4f04-af5a-caca3f2bb834"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["2/2 [==============================] - 0s 6ms/step - loss: 0.3865 - accuracy: 0.8095\n","2/2 [==============================] - 0s 6ms/step - loss: 0.6642 - accuracy: 0.7857\n","WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7f490b4c88c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","2/2 [==============================] - 0s 5ms/step - loss: 0.6113 - accuracy: 0.8571\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f490b36ba70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","2/2 [==============================] - 0s 12ms/step - loss: 0.5616 - accuracy: 0.7805\n","2/2 [==============================] - 0s 5ms/step - loss: 0.5479 - accuracy: 0.8537\n","정확도:  [0.8095238208770752, 0.7857142686843872, 0.8571428656578064, 0.7804877758026123, 0.8536585569381714]\n","정확도 평균:  0.8173054575920105\n"]}]}]}